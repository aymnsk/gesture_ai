# gesture_ai
 Core Idea:

    Use hand gestures to control a computer (mouse & keyboard).
    Recognize sign language and convert it to text/audio.
    Combine gesture-based interaction with AI-driven accessibility.

💡 Features:

✅ Sign Language Detection 🧏

    Detect ASL (American Sign Language) alphabets & words.
    Convert gestures into text & speech.

✅ Virtual Mouse & Keyboard 🖱️

    Control mouse movement & clicks with hand gestures.
    Type using a virtual keyboard with gestures.

✅ Real-Time Feedback 🔊

    Displays recognized gestures in real-time.
    Audio output for accessibility (Text-to-Speech).

🛠️ Tech Stack:

    OpenCV – For image processing.
    MediaPipe Hands – For hand tracking & gesture detection.
    TensorFlow/PyTorch – For training custom gesture models (if needed).
    PyAutoGUI – To control mouse & keyboard.
    gTTS – For converting sign language text to speech.
